# ana_sayfa.py
# Ana Sayfa
import random
import os
import hashlib
import json
import streamlit as st
from dotenv import load_dotenv
from whoosh.index import create_in, open_dir
from whoosh.fields import Schema, TEXT, NUMERIC
from whoosh.qparser import QueryParser, MultifieldParser, AndGroup
from whoosh import index
from whoosh.analysis import StandardAnalyzer
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
from io import BytesIO
import sys
import locale
import openai
import uuid
import datetime
import traceback
import time  # Typing effect iÃ§in
import fitz  # PyMuPDF for PDF page images
# db.py'den import et (VarsayalÄ±m ki db.py mevcut)
from db import init_db, save_qa, get_all_qa
# Encoding fix
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')
locale.setlocale(locale.LC_ALL, 'tr_TR.UTF-8')
load_dotenv()
# --- GLOBAL STIL VE AYARLAR ---
# Google Fonts ve Material Icons ekle
st.set_page_config(page_title="Yediulya KÃ¼tÃ¼phanesi", page_icon="ğŸ•Œ", layout="wide")
st.markdown("""
    <link href="https://fonts.googleapis.com/css2?family=Amiri:wght@400;700&family=El+Messiri:wght@400;700&family=Poppins:wght@300;400;600&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons&display=block" rel="stylesheet">
    <style>
    :root {
        --primary-color: #1e3a8a; /* Koyu mavi */
        --primary-light: #3b82f6; /* AÃ§Ä±k mavi */
        --primary-dark: #1e3a8a; /* Koyu mavi */
        --secondary-color: #f59e0b; /* Amber */
        --background-color: #f8fafc;
        --card-bg: #ffffff;
        --card-border: #e2e8f0;
        --card-shadow: rgba(0,0,0,0.05);
        --text-primary: #1e293b;
        --text-secondary: #64748b;
        --success-color: #10b981;
        --warning-color: #f59e0b;
        --error-color: #ef4444;
        --sidebar-bg: #f1f5f9;
    }
    body {
        font-family: 'Poppins', sans-serif;
        background-color: var(--background-color);
        color: var(--text-primary);
    }
    .main-title {
        text-align: center;
        margin-top: 0.5rem;
        margin-bottom: 0.25rem;
        font-family: 'El Messiri', sans-serif;
        color: var(--primary-dark);
        font-size: 2.2rem;
    }
    .bismillah {
        text-align: center;
        font-family: 'Amiri', serif;
        font-size: 1.6rem;
        margin-top: 0.25rem;
        margin-bottom: 0.25rem;
        color: #5d4037;
    }
    .hero-header {
        text-align: center;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
        font-family: 'El Messiri', sans-serif;
        color: var(--primary-dark);
    }
    .hero-subtitle {
        text-align: center;
        font-family: 'Poppins', sans-serif;
        color: var(--text-secondary);
        margin-bottom: 1.5rem;
        font-size: 1.1rem;
    }
    .features-container {
        display: flex;
        flex-wrap: wrap;
        justify-content: center;
        gap: 20px;
        margin: 2rem 0;
    }
    .feature-card {
        background-color: var(--card-bg);
        border-radius: 12px;
        box-shadow: 0 4px 6px var(--card-shadow);
        padding: 1.2rem;
        text-align: center;
        width: 160px;
        border: 1px solid var(--card-border);
        transition: all 0.2s ease;
    }
    .feature-card:hover {
        transform: translateY(-3px);
        box-shadow: 0 6px 12px var(--card-shadow);
        border-color: var(--primary-light);
    }
    .feature-icon {
        font-size: 1.8rem;
        margin-bottom: 0.7rem;
        color: var(--primary-color);
    }
    .feature-title {
        font-weight: 600;
        margin-bottom: 0.4rem;
        color: var(--text-primary);
        font-size: 1rem;
    }
    .feature-desc {
        font-size: 0.85rem;
        color: var(--text-secondary);
    }
    .login-section {
        background-color: var(--card-bg);
        padding: 2rem;
        border-radius: 15px;
        box-shadow: 0 8px 16px var(--card-shadow);
        text-align: center;
        width: 100%;
        max-width: 400px;
        border: 1px solid var(--card-border);
        margin: auto;
    }
    .login-title {
        color: var(--primary-color);
        margin-bottom: 1rem;
        font-size: 1.5rem;
    }
    .login-subtitle {
        margin-bottom: 1.5rem;
        color: var(--text-secondary);
    }
    .source-card {
        border: 1px solid var(--card-border);
        border-radius: 10px;
        padding: 15px;
        margin-bottom: 15px;
        background-color: var(--card-bg);
        transition: box-shadow 0.2s;
        box-shadow: 0 1px 3px var(--card-shadow);
    }
    .source-card:hover {
        box-shadow: 0 4px 8px var(--card-shadow);
    }
    .card-header {
        display: flex;
        justify-content: space-between;
        align-items: flex-start;
        margin-bottom: 10px;
    }
    .card-header h4 {
        margin: 0;
        font-size: 1.05rem;
        color: var(--primary-color);
    }
    .author-badge {
        background-color: #dbeafe; /* bg-blue-100 */
        color: var(--primary-color);
        padding: 3px 8px;
        border-radius: 12px;
        font-size: 0.8rem;
        white-space: nowrap;
    }
    .card-content .page-info {
        font-size: 0.85rem;
        color: var(--text-secondary);
        margin-bottom: 6px;
    }
    .card-content .book-info {
        font-size: 0.85rem;
        color: var(--text-secondary);
        margin-bottom: 6px;
    }
    .card-content .excerpt {
        font-size: 0.9rem;
        line-height: 1.5;
        color: var(--text-primary);
    }
    mark {
        background-color: #fef3c7; /* bg-amber-100 */
        padding: 0 2px;
        border-radius: 2px;
    }
    .footer {
        text-align: center;
        padding: 20px;
        color: var(--text-secondary);
        font-size: 0.85rem;
        border-top: 1px solid var(--card-border);
        margin-top: auto;
    }
    /* Sidebar styling */
    section[data-testid='stSidebar'] {
        background-color: var(--sidebar-bg);
    }
    .sidebar-header {
        font-size: 1.2rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
        color: var(--primary-dark);
    }
    /* Chat input styling */
    div[data-testid='stChatInput'] {
        border: 1px solid var(--card-border);
        border-radius: 8px;
    }
    /* Expander styling */
    div[data-testid='stExpander'] {
        border: 1px solid var(--card-border);
        border-radius: 8px;
    }
    div[data-testid='stExpander'] > div:first-child {
        background-color: var(--card-bg);
        border-radius: 8px 8px 0 0;
    }
    /* Button styling */
    button[kind='secondary'] {
        background-color: var(--card-bg);
        border: 1px solid var(--card-border);
    }
    /* Metric styling */
    div[data-testid='stMetricValue'] {
        font-size: 1.2rem;
    }
    </style>
""", unsafe_allow_html=True)
# --- ÅÄ°FRE KONTROLÃœ VE GÄ°RÄ°Å EKRANI ---
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False
if not st.session_state.authenticated:
    # Qwen.ai tarzÄ± modern ve bilgilendirici giriÅŸ ekranÄ±
    st.markdown('<div class="bismillah">Ø¨ÙØ³Ù’Ù…Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø§Ù„Ø±ÙÙ‘Ø­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±ÙÙ‘Ø­ÙÙŠÙ…Ù</div>', unsafe_allow_html=True)
    st.markdown('<h1 class="hero-header">ğŸ•Œ Yediulya KÃ¼tÃ¼phanesi</h1>', unsafe_allow_html=True)
    st.markdown('<p class="hero-subtitle">Ä°lm-i LedÃ¼n hazinelerine eriÅŸim kapÄ±sÄ±</p>', unsafe_allow_html=True)
    # Ã–zellikler / Kartlar
    st.markdown("""
    <div class="features-container">
        <div class="feature-card">
            <div class="feature-icon">ğŸ“š</div>
            <div class="feature-title">Derin Arama</div>
            <div class="feature-desc">Ãœstadlardan alÄ±ntÄ±lar</div>
        </div>
        <div class="feature-card">
            <div class="feature-icon">ğŸ”</div>
            <div class="feature-title">AnlamlÄ± Filtre</div>
            <div class="feature-desc">Yazar ve kavrama gÃ¶re</div>
        </div>
        <div class="feature-card">
            <div class="feature-icon">ğŸ§ </div>
            <div class="feature-title">AI Sentezi</div>
            <div class="feature-desc">Ä°rfanÄ± derler, sentezler</div>
        </div>
        <div class="feature-card">
            <div class="feature-icon">ğŸ›¡ï¸</div>
            <div class="feature-title">Gizli EriÅŸim</div>
            <div class="feature-desc">Ã–zel bilgi, Ã¶zel eriÅŸim</div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    # GiriÅŸ AlanÄ±
    st.markdown("""
    <div class="login-section">
        <h2 class="login-title">ğŸ”’ Ã–zel EriÅŸim</h2>
        <p class="login-subtitle">Bu kÃ¼tÃ¼phaneye eriÅŸim iÃ§in ÅŸifre girin.</p>
    """, unsafe_allow_html=True)
    password = st.text_input("ğŸ” Åifre", type="password", placeholder="Åifrenizi girin", key="login_password")
    if st.button(" GiriÅŸ Yap ", use_container_width=True, type="primary", key="login_button"):
        if password == os.getenv("APP_PASSWORD", "yediulya"):
            st.session_state.authenticated = True
            # GiriÅŸ baÅŸarÄ±lÄ± mesajÄ± ve yÃ¼kleme animasyonu
            with st.spinner("âœ… GiriÅŸ baÅŸarÄ±lÄ±! Veriler yÃ¼kleniyor, lÃ¼tfen bekleyin..."):
                time.sleep(2) # KullanÄ±cÄ±ya bekleme hissi vermek iÃ§in kÄ±sa bir gecikme
            st.rerun()
        else:
            st.error("âŒ YanlÄ±ÅŸ ÅŸifre. Tekrar deneyin.")
    st.markdown("</div>", unsafe_allow_html=True) # login-section kapanÄ±ÅŸÄ±
    st.stop()
# --- ANA SAYFA Ä°Ã‡ERÄ°ÄÄ° (GÄ°RÄ°Å BAÅARILIYSA) ---
# Bismillah - SayfanÄ±n en Ã¼stÃ¼nde ve merkezi, gÃ¶rsel olarak belirgin
st.markdown('<div class="bismillah">Ø¨ÙØ³Ù’Ù…Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø§Ù„Ø±ÙÙ‘Ø­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±ÙÙ‘Ø­ÙÙŠÙ…Ù</div>', unsafe_allow_html=True)
# Ana baÅŸlÄ±k - Bismillah'Ä±n hemen altÄ±nda
st.markdown('<h1 class="main-title">ğŸ•Œ Yediulya KÃ¼tÃ¼phanesi</h1>', unsafe_allow_html=True)
# --- YÃœKLEME MESAJLARI VE DÄ°NAMÄ°K VERÄ°LER ---
LOADING_MESSAGES = [
    "Ä°lm-i LedÃ¼n madenini kazÄ±yoruz... ğŸ“œ",
    "Manevi detaylar derleniyor... ğŸŒ¿",
    "AlÄ±ntÄ±lar tasnif ediliyor... ğŸ•Œ",
    "Ä°rfan sentezi hazÄ±rlanÄ±yor... âœ¨",
    "Tasavvuf incileri toplanÄ±yor... ğŸ’",
    "Ruhani bilgiler yÃ¼kleniyor... â˜ªï¸",
    "Hikmet kapÄ±larÄ± aÃ§Ä±lÄ±yor... ğŸ”‘"
]
TASAVVUF_TAVSIYELER = [
    "Kalbinizi rabÄ±ta ile arÄ±ndÄ±rÄ±n.",
    "Zikr ile ruhunuzu yÃ¼kseltin.",
    "SabÄ±r, tasavvufun anahtarÄ±dÄ±r.",
    "Ä°lim, amelsiz faydasÄ±zdÄ±r.",
    "MÃ¼rÅŸid, yol gÃ¶stericidir.",
    "TevekkÃ¼l, huzurun kapÄ±sÄ±dÄ±r.",
    "ÅÃ¼kÃ¼r, nimetin artmasÄ±dÄ±r."
]
HADISLER = [
    "Hadis: 'Ä°lim Ã¶ÄŸrenmek her MÃ¼slÃ¼mana farzdÄ±r.'",
    "Hadis: 'Allah'Ä± zikreden kalp diridir.'",
    "Hadis: 'Sabreden zafer bulur.'",
    "Hadis: 'En hayÄ±rlÄ± amel, ihlastÄ±r.'"
]
AYETLER = [
    "Ayet: 'Allah sabredenlerle beraberdir.' (Bakara 153)",
    "Ayet: 'Zikrullah kalplerin huzurudur.' (Ra'd 28)",
    "Ayet: 'Rabbinizi zikredin.' (Araf 205)"
]
ORNEK_SORULAR = [
    "RabÄ±ta nedir?",
    "ZikrullahÄ±n Ã¶nemi?",
    "MÃ¼rÅŸid-i Kamil Ã¶zellikleri?",
    "Tasavvuf tarihi?",
    "Sufi yollarÄ±?",
    "TevekkÃ¼lÃ¼n anlamÄ±?",
    "Ä°hlas nedir?"
]
os.makedirs("faiss_index", exist_ok=True)
os.makedirs("whoosh_index", exist_ok=True)
pdf_hash_file = "pdf_hash.json"
# Whoosh Schema
schema = Schema(
    book=TEXT(stored=True),
    author=TEXT(stored=True),
    page=NUMERIC(stored=True),
    content=TEXT(stored=True, analyzer=StandardAnalyzer()),
    pdf_file=TEXT(stored=True)
)
ix = create_in("whoosh_index", schema) if not index.exists_in("whoosh_index") else open_dir("whoosh_index")
# --- YARDIMCI FONKSÄ°YONLAR ---
def get_pdf_hash(pdf_folder):
    hash_dict = {}
    for pdf_file in sorted(os.listdir(pdf_folder)):
        if pdf_file.endswith(".pdf"):
            file_path = os.path.join(pdf_folder, pdf_file)
            hasher = hashlib.md5()
            with open(file_path, "rb") as f:
                hasher.update(f.read())
            hash_dict[pdf_file] = hasher.hexdigest()
    return hash_dict
def load_saved_hash():
    if os.path.exists(pdf_hash_file):
        with open(pdf_hash_file, "r") as f:
            return json.load(f)
    return {}
def save_hash(hash_dict):
    with open(pdf_hash_file, "w") as f:
        json.dump(hash_dict, f)
@st.cache_resource(show_spinner=False, max_entries=10)
def build_data_havuzu():
    pdf_folder = "pdfler"
    current_hash = get_pdf_hash(pdf_folder)
    saved_hash = load_saved_hash()
    index_exists = (
        index.exists_in("whoosh_index") and 
        os.path.exists(os.path.join("faiss_index", "index.faiss")) and 
        os.path.exists(os.path.join("faiss_index", "index.pkl"))
    )
    rebuild = current_hash != saved_hash or not index_exists
    authors = set()
    docs = []
    if rebuild:
        with st.spinner(random.choice(LOADING_MESSAGES)):
            info_placeholder = st.empty()
            info_placeholder.info("ğŸ“š Veri havuzu yeniden inÅŸa ediliyor. Bu iÅŸlem birkaÃ§ dakika sÃ¼rebilir...")
            progress_bar = st.progress(0)
            progress_text = st.empty()
            writer = ix.writer()
            from langchain_community.embeddings import HuggingFaceEmbeddings
            embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
            from langchain.text_splitter import RecursiveCharacterTextSplitter
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
            from langchain_community.document_loaders import PyMuPDFLoader
            pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith(".pdf")]
            for i, pdf_file in enumerate(pdf_files):
                progress = (i + 1) / len(pdf_files)
                progress_bar.progress(progress)
                progress_text.text(f"ğŸ“– Ä°ÅŸleniyor: {pdf_file} ({int(progress * 100)}%)")
                base_name = pdf_file.replace(".pdf", "").replace("_", " ")
                if "-" in base_name:
                    book_part, author_part = base_name.split("-", 1)
                    book_name = book_part.strip().title()
                    author = author_part.strip().title() + " Hz.leri"
                else:
                    book_name = base_name.title()
                    author = "Bilinmeyen MÃ¼rÅŸid"
                authors.add(author.title())
                loader = PyMuPDFLoader(os.path.join(pdf_folder, pdf_file))
                pdf_docs = loader.load()
                for doc in pdf_docs:
                    page_num = doc.metadata.get("page", 0) + 1
                    content = doc.page_content.strip()
                    if content:
                        writer.add_document(
                            book=book_name.lower(), 
                            author=author.lower(), 
                            page=page_num, 
                            content=content.lower(), 
                            pdf_file=pdf_file.lower()
                        )
                        doc.metadata["book"] = book_name
                        doc.metadata["author"] = author
                        doc.metadata["pdf_file"] = pdf_file
                        docs.append(doc)
            writer.commit()
            chunks = text_splitter.split_documents(docs)
            from langchain_community.vectorstores import FAISS
            vectorstore = FAISS.from_documents(chunks, embeddings)
            vectorstore.save_local("faiss_index")
            save_hash(current_hash)
            # Temizleme
            info_placeholder.empty()
            progress_bar.empty()
            progress_text.empty()
            st.toast("âœ… Veri havuzu baÅŸarÄ±yla oluÅŸturuldu!", icon='ğŸ‰')
    else:
        from langchain_community.embeddings import HuggingFaceEmbeddings
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        from langchain_community.vectorstores import FAISS
        vectorstore = FAISS.load_local(
            "faiss_index", 
            embeddings, 
            allow_dangerous_deserialization=True
        )
        with ix.searcher() as searcher:
            all_docs = searcher.documents()
            for doc in all_docs:
                authors.add(doc.get("author").title())
    return vectorstore, sorted(authors)
def create_word_doc(data):
    if not data:
        return None
    doc = Document()
    doc.add_heading('Yediulya KÃ¼tÃ¼phanesi SonuÃ§larÄ±', level=1).alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph(f"Tarih: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}").alignment = WD_ALIGN_PARAGRAPH.CENTER
    table = doc.add_table(rows=1, cols=len(data[0]))
    table.style = 'Table Grid'
    hdr_cells = table.rows[0].cells
    for i, key in enumerate(data[0].keys()):
        hdr_cells[i].text = key
        hdr_cells[i].paragraphs[0].runs[0].bold = True
        hdr_cells[i].paragraphs[0].runs[0].font.size = Pt(12)
    for row in data:
        row_cells = table.add_row().cells
        for i, value in enumerate(row.values()):
            row_cells[i].text = str(value)
            row_cells[i].paragraphs[0].runs[0].font.size = Pt(11)
    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio
def get_retriever(vectorstore, selected_authors):
    metadata_filter = {}
    if selected_authors:
        metadata_filter["author"] = {"$in": [a.lower() for a in selected_authors]}
    return vectorstore.as_retriever(
        search_kwargs={"k": 50, "filter": metadata_filter if metadata_filter else None}
    )
def highlight_query(text, query):
    if not query:
        return text
    # Daha basit bir vurgulama, tÃ¼m kelimeleri vurgular
    for word in query.split():
        text = text.replace(word, f'<mark>{word}</mark>')
    return text
def show_page_image(pdf_path, page_num):
    try:
        doc = fitz.open(pdf_path)
        page = doc.load_page(page_num - 1)
        pix = page.get_pixmap(dpi=100)  # DPI optimized
        img_bytes = pix.tobytes("png")
        st.image(img_bytes, use_container_width=True)
        doc.close()
    except Exception as e:
        st.error(f"Sayfa resmi yÃ¼klenemedi: {str(e)}")
def display_assistant(message, query=None):
    result_type = message.get("result_type")
    if result_type == "Veri Arama":
        data = message.get("data", [])
        if data:
            st.subheader("ğŸ“‹ Tam AlÄ±ntÄ± Listesi")
            if len(data) > 100:
                st.warning(f"ğŸ“Š {len(data)} sonuÃ§. Ä°lk 100 gÃ¶steriliyor.")
                data = data[:100]
            st.info(f"ğŸ” {len(data)} adet alÄ±ntÄ± bulundu")
            # Filtreleme seÃ§enekleri - MesajÄ±n altÄ±nda, daha kullanÄ±cÄ± dostu
            with st.expander("ğŸ”§ SÄ±ralama & GÃ¶rÃ¼nÃ¼m", expanded=False):
                 col1, col2 = st.columns([3, 1])
                 with col1:
                      sort_option = st.selectbox(
                          "ğŸ“Š SÄ±ralama", 
                          ["Alaka DÃ¼zeyi", "Sayfa NumarasÄ±", "Kitap AdÄ±"], 
                          key=f"sort_{message.get('unique_id')}"
                      )
                 with col2:
                      view_option = st.radio("ğŸ‘ï¸ GÃ¶rÃ¼nÃ¼m", ["Kartlar", "Tablo"], horizontal=True, key=f"view_{message.get('unique_id')}")
            # SÄ±ralama iÅŸlemi
            if sort_option == "Sayfa NumarasÄ±":
                data = sorted(data, key=lambda x: x["Sayfa"])
            elif sort_option == "Kitap AdÄ±":
                data = sorted(data, key=lambda x: x["Kitap"])
            # Alaka dÃ¼zeyi zaten varsayÄ±lan sÄ±ralama
            # Responsive kolon sayÄ±sÄ±
            if view_option == "Kartlar":
                # Ekran geniÅŸliÄŸine gÃ¶re kolon sayÄ±sÄ±nÄ± ayarla
                screen_width = st.get_option("browser.gatherUsageStats") # Basit bir kontrol
                if screen_width:
                     # Bu kÄ±sÄ±m tam olarak doÄŸru Ã§alÄ±ÅŸmaz, ama mantÄ±k budur.
                     # GerÃ§ek responsive iÃ§in JS entegrasyonu gerekebilir.
                     # Burada basitleÅŸtirilmiÅŸ bir yaklaÅŸÄ±m kullanÄ±yoruz.
                     # Genellikle Streamlit'in yerleÅŸik responsive davranÄ±ÅŸÄ± iÅŸ gÃ¶rÃ¼r.
                     # Ama burada manuel ayar yapmak isteyebiliriz.
                     # Ã–rnek: 768px altÄ± mobil, 768-1024 tablet, 1024+ masaÃ¼stÃ¼
                     # Streamlit'te bu tam olarak yapÄ±lamaz, bu yÃ¼zden sabit tutuyoruz.
                     # Ancak, kullanÄ±cÄ± deneyimi iÃ§in kÃ¼Ã§Ã¼k ekranlarda 1 kolon daha iyi olabilir.
                     # Bu Ã¶rnek, geliÅŸtirme fikri vermek iÃ§indir.
                     num_cols = 3 # VarsayÄ±lan
                else:
                     num_cols = 3
            else: # Tablo
                num_cols = 1

            cols = st.columns(num_cols)
            for i, item in enumerate(data):
                with cols[i % num_cols]:
                    st.markdown(f"""
                    <div class="source-card">
                        <div class="card-header">
                            <h4>{item['Kitap']}</h4>
                            <span class="author-badge">{item['Yazar/Åahsiyet']}</span>
                        </div>
                        <div class="card-content">
                            <p class="page-info">ğŸ“„ Sayfa: {item['Sayfa']}</p>
                            <p class="excerpt">{highlight_query(item["Tam Metin (AlÄ±ntÄ±)"][:200] + "...", query)}</p>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    with st.expander("ğŸ“– Sayfa Resmini GÃ¶r"):
                        pdf_path = os.path.join("pdfler", item["PDF File"])
                        show_page_image(pdf_path, item["Sayfa"])
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            word_doc = create_word_doc(data)
            if word_doc:
                st.download_button("ğŸ’¾ Word Ä°ndir", word_doc, f"ilm_havuzu_{timestamp}.docx", key=message.get('unique_id'))
        else:
            st.info("ğŸ“­ SonuÃ§ bulunamadÄ±.")
    elif result_type == "AI Ä°rfan Sentezi":
        content = message.get("content", "")
        sources = message.get("sources", [])
        # AI sentezi iÃ§in daha akÄ±cÄ± yazÄ±m efekti
        with st.chat_message("assistant"):
            container = st.empty()
            displayed_text = ""
            for char in content:
                displayed_text += char
                container.markdown(displayed_text)
                # time.sleep(0.005) # Ã‡ok hÄ±zlÄ± olmasÄ± iÃ§in yorum satÄ±rÄ±na alÄ±ndÄ±
        with st.expander("ğŸ“š Kaynaklar (Grid Kartlar)", expanded=False):
            if sources:
                books = list(set([s.get('book') for s in sources if s.get('book')]))
                authors = list(set([s.get('author') for s in sources if s.get('author')]))
                col1, col2, col3 = st.columns(3)
                col1.metric("ğŸ“š Kitap", len(books))
                col2.metric("ğŸ‘¤ Yazar", len(authors))
                col3.metric("ğŸ“ AlÄ±ntÄ±", len(sources))
            num_cols = 2
            cols = st.columns(num_cols)
            for i, doc in enumerate(sources):
                with cols[i % num_cols]:
                    st.markdown(f"""
                        <div class="source-card">
                            <div class="card-header">
                                <h4>Kaynak {i+1}</h4>
                                <span class="author-badge">{doc.get('author')}</span>
                            </div>
                            <div class="card-content">
                                <p class="book-info">ğŸ“– {doc.get('book')}</p>
                                <p class="page-info">ğŸ“„ Sayfa: {doc.get('page')}</p>
                                <p class="excerpt">{highlight_query(doc.get('page_content')[:150] + "...", query)}</p>
                            </div>
                        </div>
                    """, unsafe_allow_html=True)
                    if 'pdf_file' in doc:
                        with st.expander("ğŸ” Sayfa Resmini GÃ¶r"):
                            pdf_path = os.path.join("pdfler", doc['pdf_file'])
                            show_page_image(pdf_path, doc.get('page'))
    else:
        st.markdown(message.get("content", ""))
def load_qa(question, answer):
    st.session_state.messages = [
        {"role": "user", "content": question},
        {"role": "assistant", "content": answer, "result_type": "AI Ä°rfan Sentezi"}
    ]
    st.rerun()
def ask_data_havuzu(question: str, vectorstore, selected_authors, result_type):
    start_time = time.time()
    with st.spinner(random.choice(LOADING_MESSAGES)):
        try:
            retriever = get_retriever(vectorstore, selected_authors)
            assistant_message = {"role": "assistant", "result_type": result_type, "unique_id": str(uuid.uuid4())}
            if result_type == "Veri Arama":
                data = []
                with ix.searcher() as searcher:
                    parser = MultifieldParser(["author", "content"], schema=ix.schema, group=AndGroup)
                    query_parts = []
                    if selected_authors:
                        author_query = " OR ".join([f'author:"{a.lower()}"' for a in selected_authors])
                        query_parts.append(f"({author_query})")
                    if question:
                        query_parts.append(f'content:{question.lower()}')
                    full_query_str = " AND ".join(query_parts) if query_parts else "*"
                    q = parser.parse(full_query_str)
                    results = searcher.search(q, limit=100)
                    seen = set()
                    for hit in results:
                        unique_key = f"{hit['book']}_{hit['page']}_{hit['content'][:50]}"
                        if unique_key not in seen:
                            seen.add(unique_key)
                            data.append({
                                "Kitap": hit["book"].title(),
                                "Yazar/Åahsiyet": hit["author"].title(),
                                "Sayfa": hit["page"],
                                "Tam Metin (AlÄ±ntÄ±)": hit["content"],
                                "PDF File": hit["pdf_file"]
                            })
                if question:
                    query_lower = question.lower()
                    data = sorted(data, key=lambda x: x["Tam Metin (AlÄ±ntÄ±)"].lower().count(query_lower), reverse=True)
                assistant_message["data"] = data
            elif result_type == "AI Ä°rfan Sentezi":
                deepseek_api_key = os.getenv("DEEPSEEK_API_KEY")
                if not deepseek_api_key:
                    raise ValueError("API anahtarÄ± yok!")
                client = openai.OpenAI(base_url="https://api.deepseek.com", api_key=deepseek_api_key)
                relevant_docs = retriever.get_relevant_documents(question)
                context = "\n".join([doc.page_content for doc in relevant_docs])
                messages = [
                    {"role": "system", "content": """Sen bir tasavvuf Ã¢limi ve uzmanÄ±sÄ±n. CevabÄ±nÄ± SADECE verilen alÄ±ntÄ±lara dayalÄ± oluÅŸtur; dÄ±ÅŸ bilgi, genel tasavvuf bilgisi veya kiÅŸisel yorum ekleme. Verilen alÄ±ntÄ±lar dÄ±ÅŸÄ±ndaki hiÃ§bir Ã¼stat, kitap veya kavramÄ± kullanma.
Sorulan kavramÄ± tasavvuf baÄŸlamÄ±nda sentezle. YanÄ±tÄ±nÄ± ÅŸu yapÄ±ya gÃ¶re organize et:
Anlam, KÃ¶ken ve Ã–nem: KavramÄ±n anlamÄ±nÄ±, kÃ¶kenini ve tasavvuftaki Ã¶nemini kÄ±saca sentezle (bu kÄ±sÄ±m yanÄ±tÄ±n %20'sini geÃ§mesin). ArdÄ±ndan, verilen alÄ±ntÄ±lardaki Ã¼statlardan doÄŸrudan alÄ±ntÄ±larla destekle. Her alÄ±ntÄ±da Ã¼stadÄ±n adÄ±nÄ±, kitabÄ±nÄ± ve sayfasÄ±nÄ± belirt (Ã¶rneÄŸin: "Ali Ramazan DinÃ§ Efendi, SeyrsÃ¼lÃ¼k, sayfa X: 'AlÄ±ntÄ± metni.'"). EÄŸer sayfa belirtilmemiÅŸse, sadece kitap adÄ±nÄ± belirt.
GÃ¶rÃ¼ÅŸlerin DetaylandÄ±rÄ±lmasÄ± ve KarÅŸÄ±laÅŸtÄ±rmasÄ±: Verilen alÄ±ntÄ±lardaki Ã¼statlarÄ±n gÃ¶rÃ¼ÅŸlerini detaylandÄ±r ve farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ±nÄ± karÅŸÄ±laÅŸtÄ±r. Her detayÄ±, ilgili Ã¼statlardan doÄŸrudan alÄ±ntÄ±larla somutlaÅŸtÄ±r. KarÅŸÄ±laÅŸtÄ±rmalarda alÄ±ntÄ±larÄ± yan yana koyarak analiz et (Ã¶rneÄŸin: "HacÄ± Hasan Efendi ÅŸÃ¶yle derken, Ali Ramazan DinÃ§ Efendi ÅŸu ÅŸekilde farklÄ± vurgular.").
BoyutlarÄ±n Analizi: KavramÄ±n manevi, pratik ve felsefi boyutlarÄ±nÄ± analiz et. Her boyutu, verilen alÄ±ntÄ±lardaki Ã¼stad yazÄ±larÄ±nÄ±n doÄŸrudan alÄ±ntÄ±larÄ± ve Ã¶rnekleriyle destekle. Analizini alÄ±ntÄ±lara dayandÄ±r, kendi sentezini minimum tut.
YanÄ±tÄ±nÄ±n genel kurallarÄ±:
%80'i verilen alÄ±ntÄ±lardan DOÄRUDAN alÄ±ntÄ±lar olsun (tam metin alÄ±ntÄ±larÄ± kullan, kÄ±saltma).
%20'i sentez olsun (alÄ±ntÄ±larÄ± baÄŸlamak, karÅŸÄ±laÅŸtÄ±rmak veya Ã¶zetlemek iÃ§in).
Her paragrafta en az bir alÄ±ntÄ± kullan ve Ã¼stadÄ± alÄ±ntÄ±layarak analiz et.
YanÄ±tÄ± nesnel, akademik ve Ã¼stat odaklÄ± tut; Ã¶rnekler sadece verilen alÄ±ntÄ±lardan gelsin.
EÄŸer verilen alÄ±ntÄ±larda yeterli detay yoksa, "Verilen eserlerde bu kavram iÃ§in yeterli detay yok." diye belirt."""},
                    {"role": "user", "content": f"AlÄ±ntÄ±lar: {context}\nSoru: {question}"}
                ]
                stream = client.chat.completions.create(
                    model="deepseek-chat",
                    messages=messages,
                    temperature=0.5,
                    max_tokens=1500,
                    stream=True
                )
                answer = ""
                with st.chat_message("assistant"):
                    container = st.empty()
                    for chunk in stream:
                        if chunk.choices[0].delta.content is not None:
                            answer += chunk.choices[0].delta.content
                            container.markdown(answer)
                            # time.sleep(0.01) # HÄ±zlÄ± yazÄ±m iÃ§in yorum satÄ±rÄ±na alÄ±ndÄ±
                assistant_message["content"] = answer
                assistant_message["sources"] = [
                    {"book": doc.metadata.get("book"), "author": doc.metadata.get("author"), "page": doc.metadata.get("page"), "page_content": doc.page_content, "pdf_file": doc.metadata.get("pdf_file")}
                    for doc in relevant_docs if "pdf_file" in doc.metadata
                ]
                if answer:
                    save_qa(question, answer)
            st.session_state.messages.append(assistant_message)
            if len(st.session_state.messages) > 20:
                st.warning("âš ï¸ GeÃ§miÅŸ 20 mesajla sÄ±nÄ±rlÄ±. Eski mesajlar silindi.")
                st.session_state.messages = st.session_state.messages[-20:]
            end_time = time.time()
            st.success(f"âœ… YanÄ±t {end_time - start_time:.1f} saniyede hazÄ±rlandÄ±")
            st.rerun() # UI'Ä±n yeni mesajla yeniden yÃ¼klenmesini zorla
        except Exception as e:
            st.error(f"âŒ Hata oluÅŸtu: {str(e)}. LÃ¼tfen filtreleri kontrol edin veya tekrar deneyin.")
            with st.expander("ğŸ”§ Hata DetayÄ±"):
                st.code(traceback.format_exc())
            if st.button("ğŸ”„ Tekrar Dene"):
                st.rerun()
# --- UYGULAMA AKIÅI ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ğŸ‘‹ HoÅŸ geldiniz! Sorgu girin."}]
if not os.getenv("DEEPSEEK_API_KEY"):
    st.error("ğŸ”‘ API anahtarÄ± ekleyin!")
    st.stop()
init_db()
vectorstore, authors = build_data_havuzu()
st.session_state.vectorstore = vectorstore
st.session_state.authors = authors
# --- FÄ°LTRELER ÃœSTTE ---
st.markdown("---")
with st.expander("ğŸ” Filtreler", expanded=True):
    col1, col2, col3 = st.columns([3, 2, 2]) # Ekstra kolon Ã¶rnek sorular iÃ§in
    with col1:
        selected_authors_inline = st.multiselect("Ãœstadlar", authors, key="ana_authors_select_inline", placeholder="MÃ¼rÅŸid(ler) seÃ§in...")
    with col2:
        result_type_inline = st.radio("ğŸ¯ SonuÃ§ TÃ¼rÃ¼", ["Veri Arama", "AI Sentezi"], key="ana_result_type_inline", horizontal=True)
    with col3:
        # Ã–rnek Sorular
        with st.popover("ğŸ’¡ Ã–rnek Sorular"):
            st.markdown("**HÄ±zlÄ± BaÅŸlangÄ±Ã§:**")
            for soru in ORNEK_SORULAR:
                if st.button(soru, key=f"ornek_soru_{soru}"):
                    st.session_state.ana_chat_input_main = soru
                    st.rerun() # SayfayÄ± yeniden yÃ¼kleyerek sohbet alanÄ±na soruyu yaz
st.markdown("---")
# --- SIDEBAR - TemizlenmiÅŸ ve odaklÄ± ---
with st.sidebar:
    st.markdown('<div class="sidebar-header">âš™ï¸ MenÃ¼</div>', unsafe_allow_html=True)
    with st.expander("â­ Favoriler", expanded=False):
        if "favorites" not in st.session_state:
            st.session_state.favorites = []
        if st.session_state.favorites:
            for i, fav in enumerate(st.session_state.favorites[-10:]):
                if st.button(f"â­ {fav[:30]}...", key=f"fav_sidebar_{i}", use_container_width=True):
                    st.session_state.ana_chat_input_main = fav
                    st.rerun()
        else:
            st.info("ğŸ“­ Favori yok")
        if st.button("ğŸ“¥ Sorguyu Favorile", key="add_to_favorites_sidebar", use_container_width=True):
            if "messages" in st.session_state and len(st.session_state.messages) > 1:
                current_query = st.session_state.messages[-2]["content"]
                if current_query and current_query not in st.session_state.favorites:
                    st.session_state.favorites.append(current_query)
                    st.toast("âœ… Favorilere eklendi!", icon='âœ…')
    with st.expander("ğŸ“š GeÃ§miÅŸ Sorgular", expanded=False):
        qa_list = get_all_qa()[-20:]
        if qa_list:
            for i, qa in enumerate(qa_list):
                question, _, timestamp = qa
                unique_key = f"sidebar_qa_button_{i}_{timestamp}"
                if st.button(f"â“ {question[:35]}...", key=unique_key, use_container_width=True):
                    load_qa(question, qa[1])
        else:
            st.info("ğŸ“­ GeÃ§miÅŸ yok")
    if st.button("ğŸ—‘ï¸ GeÃ§miÅŸi Temizle", key="clear_history_sidebar", use_container_width=True):
        st.session_state.messages = [{"role": "assistant", "content": "ğŸ‘‹ HoÅŸ geldiniz! Sorgu girin."}]
        st.rerun()
    with st.expander("â“ Bilgi & Ä°puÃ§larÄ±", expanded=False):
        st.subheader("ğŸ•Œ")
        st.info(random.choice(TASAVVUF_TAVSIYELER))
        st.subheader("ğŸ“œ")
        st.info(random.choice(HADISLER))
        st.subheader("ğŸ“–")
        st.info(random.choice(AYETLER))
        st.markdown("---")
        st.markdown("**Ä°puÃ§larÄ±:**")
        st.caption("- Sorgunuzu yazdÄ±ktan sonra 'Enter' tuÅŸuna basÄ±n.")
        st.caption("- Mobil cihazda yatay tutun.")
        st.caption("- API anahtarÄ±nÄ±zÄ± kontrol edin.")
# --- SOHBET ALANI - Qwen tarzÄ± ---
main_area = st.container()
with main_area:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "user":
                st.markdown(message["content"])
            else:
                display_assistant(message, query=st.session_state.messages[-2]["content"] if len(st.session_state.messages) > 1 else None)
    if prompt := st.chat_input("ğŸ’­ Sorgu girin (Ã¶r. rabÄ±ta)...", key="ana_chat_input_main"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        ask_data_havuzu(prompt, vectorstore, selected_authors_inline, result_type_inline)
# Footer - SayfanÄ±n en altÄ±
st.markdown('<div class="footer">Â© 2025 Yediulya KÃ¼tÃ¼phanesi </div>', unsafe_allow_html=True)