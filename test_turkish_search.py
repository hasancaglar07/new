#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TÃ¼rkÃ§e Arama Sistemi Test SenaryolarÄ±

Bu script, TÃ¼rkÃ§e sesli harf uyumlarÄ± ve yazÄ±m varyasyonlarÄ± iÃ§in
oluÅŸturulan arama sisteminin kapsamlÄ± testlerini yapar.
"""

import sys
import os
import time
from pathlib import Path

# Proje kÃ¶k dizinini sys.path'e ekle
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from turkish_search_utils import (
        TurkishVowelNormalizer, 
        TurkishQueryExpander, 
        normalize_turkish_text,
        create_turkish_analyzer
    )
    print("âœ… Turkish search utilities baÅŸarÄ±yla import edildi")
except ImportError as e:
    print(f"âŒ Import hatasÄ±: {e}")
    print("LÃ¼tfen Ã¶nce gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin: pip install TurkishStemmer thefuzz python-Levenshtein")
    sys.exit(1)


class TurkishSearchTester:
    """
    TÃ¼rkÃ§e arama sistemi iÃ§in kapsamlÄ± test sÄ±nÄ±fÄ±.
    """
    
    def __init__(self):
        self.test_cases = {
            # Sesli harf varyasyonlarÄ± test cases
            'vowel_variations': [
                {
                    'base_word': 'fÃ¼yuzat',
                    'variations': ['fÃ¼yÃ»zÃ¢t', 'fÃ¼yuzat', 'fÃ¼yÃ¼zat', 'fuyÃ¼zat', 'fuyuzat', 'fÃ»yÃ¼zÃ¢t'],
                    'expected_normalized': 'fuyuzat'
                },
                {
                    'base_word': 'rabÄ±ta',
                    'variations': ['rabÄ±ta', 'rÃ¢bÄ±ta', 'rabita', 'rÃ¢bita'],
                    'expected_normalized': 'rabita'
                },
                {
                    'base_word': 'zikir',
                    'variations': ['zikir', 'zikr', 'zÃ®kir', 'zÃ®kr', 'ziker'],
                    'expected_normalized': 'zikir'
                },
                {
                    'base_word': 'mÃ¼rid',
                    'variations': ['mÃ¼rid', 'mÃ¼rÃ®d', 'murid', 'mÃ»rid'],
                    'expected_normalized': 'murid'
                },
                {
                    'base_word': 'sohbet',
                    'variations': ['sohbet', 'sÃ´hbet', 'suhbet', 'sÃ»hbet'],
                    'expected_normalized': 'sohbet'
                }
            ],
            
            # Fuzzy matching test cases
            'fuzzy_matching': [
                {
                    'query': 'fÃ¼yuzat',
                    'targets': ['fÃ¼yÃ»zÃ¢t', 'feyuzat', 'fuyuzat', 'fÃ¼yÃ¼zat'],
                    'min_similarity': 80
                },
                {
                    'query': 'rabÄ±ta',
                    'targets': ['rÃ¢bÄ±ta', 'rabita', 'rapÄ±ta', 'rabÄ±da'],
                    'min_similarity': 75
                },
                {
                    'query': 'mÃ¼rÅŸid',
                    'targets': ['mÃ¼rÅŸit', 'murÅŸid', 'mÃ¼rÅŸed', 'mÃ¼rsid'],
                    'min_similarity': 70
                }
            ],
            
            # Query expansion test cases
            'query_expansion': [
                {
                    'query': 'fÃ¼yuzat nedir',
                    'expected_variants_count': 10,  # En az 10 varyasyon bekleniyor
                    'should_contain': ['fuyuzat', 'fÃ¼yÃ¼zat']
                },
                {
                    'query': 'rabÄ±ta nasÄ±l',
                    'expected_variants_count': 8,
                    'should_contain': ['rabita', 'rÃ¢bÄ±ta']
                }
            ],
            
            # Stemming test cases (eÄŸer TurkishStemmer mevcutsa)
            'stemming': [
                {
                    'word': 'kitaplar',
                    'expected_stem': 'kitap'
                },
                {
                    'word': 'evlerden',
                    'expected_stem': 'ev'
                },
                {
                    'word': 'Ã§alÄ±ÅŸÄ±yoruz',
                    'expected_stem': 'Ã§alÄ±ÅŸ'
                }
            ]
        }
        
        self.results = {
            'passed': 0,
            'failed': 0,
            'errors': []
        }
    
    def test_vowel_normalization(self):
        """
        Sesli harf normalizasyonu testleri.
        """
        print("\nğŸ”¤ Sesli Harf Normalizasyonu Testleri")
        print("=" * 50)
        
        for test_case in self.test_cases['vowel_variations']:
            base_word = test_case['base_word']
            variations = test_case['variations']
            expected = test_case['expected_normalized']
            
            print(f"\nğŸ“ Test: {base_word} varyasyonlarÄ±")
            
            all_passed = True
            for variation in variations:
                try:
                    normalized = normalize_turkish_text(variation)
                    if normalized == expected:
                        print(f"  âœ… {variation} -> {normalized}")
                        self.results['passed'] += 1
                    else:
                        print(f"  âŒ {variation} -> {normalized} (beklenen: {expected})")
                        self.results['failed'] += 1
                        all_passed = False
                except Exception as e:
                    print(f"  âš ï¸  {variation} -> HATA: {e}")
                    self.results['errors'].append(f"Normalization error for {variation}: {e}")
                    self.results['failed'] += 1
                    all_passed = False
            
            if all_passed:
                print(f"  ğŸ‰ {base_word} tÃ¼m varyasyonlarÄ± baÅŸarÄ±lÄ±!")
    
    def test_fuzzy_matching(self):
        """
        Fuzzy matching testleri.
        """
        print("\nğŸ” Fuzzy Matching Testleri")
        print("=" * 50)
        
        expander = TurkishQueryExpander()
        
        for test_case in self.test_cases['fuzzy_matching']:
            query = test_case['query']
            targets = test_case['targets']
            min_similarity = test_case['min_similarity']
            
            print(f"\nğŸ“ Test: '{query}' ile benzerlik")
            
            for target in targets:
                try:
                    similarity = expander.calculate_similarity(query, target)
                    if similarity >= min_similarity:
                        print(f"  âœ… {target}: {similarity:.1f}% (â‰¥{min_similarity}%)")
                        self.results['passed'] += 1
                    else:
                        print(f"  âŒ {target}: {similarity:.1f}% (<{min_similarity}%)")
                        self.results['failed'] += 1
                except Exception as e:
                    print(f"  âš ï¸  {target} -> HATA: {e}")
                    self.results['errors'].append(f"Fuzzy matching error for {query}->{target}: {e}")
                    self.results['failed'] += 1
    
    def test_query_expansion(self):
        """
        Query expansion testleri.
        """
        print("\nğŸ”„ Query Expansion Testleri")
        print("=" * 50)
        
        expander = TurkishQueryExpander()
        
        for test_case in self.test_cases['query_expansion']:
            query = test_case['query']
            expected_count = test_case['expected_variants_count']
            should_contain = test_case['should_contain']
            
            print(f"\nğŸ“ Test: '{query}' geniÅŸletme")
            
            try:
                # Ä°lk kelimeyi al ve varyasyonlarÄ±nÄ± Ã¼ret
                first_word = query.split()[0]
                variants = expander.generate_vowel_variants(first_word)
                
                print(f"  ğŸ“Š Ãœretilen varyasyon sayÄ±sÄ±: {len(variants)}")
                print(f"  ğŸ“‹ Ä°lk 10 varyasyon: {variants[:10]}")
                
                # Varyasyon sayÄ±sÄ± kontrolÃ¼
                if len(variants) >= expected_count:
                    print(f"  âœ… Varyasyon sayÄ±sÄ± yeterli (â‰¥{expected_count})")
                    self.results['passed'] += 1
                else:
                    print(f"  âŒ Varyasyon sayÄ±sÄ± yetersiz (<{expected_count})")
                    self.results['failed'] += 1
                
                # Belirli varyasyonlarÄ±n varlÄ±ÄŸÄ± kontrolÃ¼
                for should_have in should_contain:
                    if should_have in variants:
                        print(f"  âœ… '{should_have}' varyasyonu mevcut")
                        self.results['passed'] += 1
                    else:
                        print(f"  âŒ '{should_have}' varyasyonu eksik")
                        self.results['failed'] += 1
                        
            except Exception as e:
                print(f"  âš ï¸  HATA: {e}")
                self.results['errors'].append(f"Query expansion error for {query}: {e}")
                self.results['failed'] += 1
    
    def test_stemming(self):
        """
        Stemming testleri (eÄŸer TurkishStemmer mevcutsa).
        """
        print("\nğŸŒ± Stemming Testleri")
        print("=" * 50)
        
        try:
            from TurkishStemmer import TurkishStemmer
            stemmer = TurkishStemmer()
            
            for test_case in self.test_cases['stemming']:
                word = test_case['word']
                expected_stem = test_case['expected_stem']
                
                try:
                    actual_stem = stemmer.stem(word)
                    if actual_stem == expected_stem:
                        print(f"  âœ… {word} -> {actual_stem}")
                        self.results['passed'] += 1
                    else:
                        print(f"  âŒ {word} -> {actual_stem} (beklenen: {expected_stem})")
                        self.results['failed'] += 1
                except Exception as e:
                    print(f"  âš ï¸  {word} -> HATA: {e}")
                    self.results['errors'].append(f"Stemming error for {word}: {e}")
                    self.results['failed'] += 1
                    
        except ImportError:
            print("  âš ï¸  TurkishStemmer mevcut deÄŸil, stemming testleri atlanÄ±yor")
    
    def test_analyzer_integration(self):
        """
        Analyzer entegrasyonu testleri.
        """
        print("\nâš™ï¸ Analyzer Entegrasyonu Testleri")
        print("=" * 50)
        
        try:
            analyzer = create_turkish_analyzer()
            
            test_texts = [
                "fÃ¼yÃ»zÃ¢t nedir",
                "rabÄ±ta nasÄ±l yapÄ±lÄ±r",
                "mÃ¼rÅŸid-i kÃ¢mil Ã¶zellikleri"
            ]
            
            for text in test_texts:
                try:
                    # Basit token oluÅŸtur
                    class SimpleToken:
                        def __init__(self, text):
                            self.text = text
                    
                    tokens = [SimpleToken(text)]
                    processed_tokens = list(analyzer(tokens))
                    
                    if processed_tokens:
                        processed_text = processed_tokens[0].text
                        print(f"  âœ… '{text}' -> '{processed_text}'")
                        self.results['passed'] += 1
                    else:
                        print(f"  âŒ '{text}' -> BOÅ SONUÃ‡")
                        self.results['failed'] += 1
                        
                except Exception as e:
                    print(f"  âš ï¸  '{text}' -> HATA: {e}")
                    self.results['errors'].append(f"Analyzer error for {text}: {e}")
                    self.results['failed'] += 1
                    
        except Exception as e:
            print(f"  âš ï¸  Analyzer oluÅŸturulamadÄ±: {e}")
            self.results['errors'].append(f"Analyzer creation error: {e}")
    
    def run_performance_tests(self):
        """
        Performans testleri.
        """
        print("\nâš¡ Performans Testleri")
        print("=" * 50)
        
        expander = TurkishQueryExpander()
        
        # Normalizasyon performansÄ±
        test_words = ['fÃ¼yÃ»zÃ¢t'] * 1000
        start_time = time.time()
        
        for word in test_words:
            normalize_turkish_text(word)
        
        normalization_time = time.time() - start_time
        print(f"  ğŸ“Š 1000 kelime normalizasyonu: {normalization_time:.3f} saniye")
        
        # Query expansion performansÄ±
        start_time = time.time()
        
        for _ in range(100):
            expander.generate_vowel_variants('fÃ¼yuzat')
        
        expansion_time = time.time() - start_time
        print(f"  ğŸ“Š 100 query expansion: {expansion_time:.3f} saniye")
        
        # Fuzzy matching performansÄ±
        start_time = time.time()
        
        for _ in range(100):
            expander.calculate_similarity('fÃ¼yuzat', 'fÃ¼yÃ»zÃ¢t')
        
        fuzzy_time = time.time() - start_time
        print(f"  ğŸ“Š 100 fuzzy matching: {fuzzy_time:.3f} saniye")
        
        # Performans deÄŸerlendirmesi
        if normalization_time < 0.1:
            print(f"  âœ… Normalizasyon performansÄ± iyi")
            self.results['passed'] += 1
        else:
            print(f"  âŒ Normalizasyon performansÄ± yavaÅŸ")
            self.results['failed'] += 1
        
        if expansion_time < 1.0:
            print(f"  âœ… Query expansion performansÄ± iyi")
            self.results['passed'] += 1
        else:
            print(f"  âŒ Query expansion performansÄ± yavaÅŸ")
            self.results['failed'] += 1
    
    def run_all_tests(self):
        """
        TÃ¼m testleri Ã§alÄ±ÅŸtÄ±rÄ±r.
        """
        print("ğŸš€ TÃ¼rkÃ§e Arama Sistemi Test SÃ¼reci BaÅŸlÄ±yor")
        print("=" * 60)
        
        start_time = time.time()
        
        # Test kategorilerini Ã§alÄ±ÅŸtÄ±r
        self.test_vowel_normalization()
        self.test_fuzzy_matching()
        self.test_query_expansion()
        self.test_stemming()
        self.test_analyzer_integration()
        self.run_performance_tests()
        
        total_time = time.time() - start_time
        
        # SonuÃ§larÄ± Ã¶zetle
        print("\n" + "=" * 60)
        print("ğŸ“Š TEST SONUÃ‡LARI")
        print("=" * 60)
        
        total_tests = self.results['passed'] + self.results['failed']
        success_rate = (self.results['passed'] / total_tests * 100) if total_tests > 0 else 0
        
        print(f"âœ… BaÅŸarÄ±lÄ± testler: {self.results['passed']}")
        print(f"âŒ BaÅŸarÄ±sÄ±z testler: {self.results['failed']}")
        print(f"ğŸ“ˆ BaÅŸarÄ± oranÄ±: {success_rate:.1f}%")
        print(f"â±ï¸  Toplam sÃ¼re: {total_time:.2f} saniye")
        
        if self.results['errors']:
            print(f"\nâš ï¸  HATALAR ({len(self.results['errors'])})")
            for i, error in enumerate(self.results['errors'], 1):
                print(f"  {i}. {error}")
        
        # Genel deÄŸerlendirme
        if success_rate >= 90:
            print("\nğŸ‰ MÃœKEMMEL! Sistem tÃ¼m testleri baÅŸarÄ±yla geÃ§ti.")
        elif success_rate >= 75:
            print("\nâœ… Ä°YÄ°! Sistem Ã§oÄŸu testi geÃ§ti, kÃ¼Ã§Ã¼k iyileÅŸtirmeler yapÄ±labilir.")
        elif success_rate >= 50:
            print("\nâš ï¸  ORTA! Sistem temel iÅŸlevleri yerine getiriyor, iyileÅŸtirmeler gerekli.")
        else:
            print("\nâŒ KÃ–TÃœ! Sistem ciddi sorunlar iÃ§eriyor, gÃ¶zden geÃ§irilmeli.")
        
        return success_rate >= 75


def main():
    """
    Ana test fonksiyonu.
    """
    tester = TurkishSearchTester()
    success = tester.run_all_tests()
    
    # Ã‡Ä±kÄ±ÅŸ kodu
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()